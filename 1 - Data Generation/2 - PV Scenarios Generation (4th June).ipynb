{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PV Scenarios Generation:\n",
    "\n",
    "### 0) Script Initialization\n",
    "    A) Workspace and Package Intialization\n",
    "    B) Function Definition\n",
    "\t\n",
    "### 1) Secondly Data Processing\n",
    "\tA) Secondly Data Loading\n",
    "\tB) Secondly Data Aggregation\n",
    "\tC) Perfect Forecast Formation\n",
    "\tD) Clody - Clear-sky Intervals Separation\n",
    "\tE) Model Fitting\n",
    "\t\n",
    "### 2) Scenario Generation\n",
    "    A) Initialize the scenario matrices\n",
    "    B) Separate the cloudy and clearsky\n",
    "    C) Generate 24h ahead scenarios for each EMS period\n",
    "    D) Save the obtained data\n",
    "__________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0) Script Initialization\n",
    "    A) Workspace and Package Intialization\n",
    "    B) Function Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.A) Workspace Initialization\n",
    "\n",
    "# Clear the workspace\n",
    "rm(list=ls()) # remove all variables from workspace\n",
    "set.seed(12345)\n",
    "\n",
    "#######################################################\n",
    "# REDUCE THE GENERATION by 15% !!! (for better match) #\n",
    "#######################################################\n",
    "GEN_REDUCTION <- 0.85\n",
    "\n",
    "# Parameter initialization:\n",
    "\n",
    "var.treshold <- 200000\n",
    "\n",
    "n_scen = 5\n",
    "t.ems = 15           # EMS period in [min]\n",
    "t.ems.seg = 60*t.ems # EMS period in [s]\n",
    "t.int = 1.0          # Intra period in [min]\n",
    "t.int.seg = 60*t.int # Intra period in [s]\n",
    "t.for = 30           # Forecast period in [min]\n",
    "t.for.seg = 60*t.for # Forecast period in [s]\n",
    "\n",
    "my.resolution = t.for/t.ems\n",
    "my.41 = (24*60/t.ems)/my.resolution\n",
    "my.2880 = 24*60/t.int\n",
    "my.288 = 24*60/t.ems\n",
    "\n",
    "\n",
    "# Load packages:\n",
    "require(R.matlab)\n",
    "require(xlsx)\n",
    "require(ggplot2)\n",
    "require(reshape2)\n",
    "require(forecast)\n",
    "require(nleqslv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0.B) - Function definition:\n",
    "\n",
    "# enlarge: Given a small vector it creates a larger one by repeating its components\n",
    "# small       <- original vector \n",
    "# large.val   <- times we want to multiply it\n",
    "enlarge <- function(small,large.val)\n",
    "{\n",
    "  large <- 0\n",
    "  for(i in 1:length(small)){\n",
    "    large <- c(large,rep(small[i],large.val))\n",
    "  }       \n",
    "  large <- large[-1]\n",
    "  return(large)\n",
    "}\n",
    "\n",
    "# chunk: Given a vector it divides it\n",
    "# x     <- original vector\n",
    "# n     <- number of subvectors generated\n",
    "chunk <- function(x,n) \n",
    "{\n",
    "  split(x, cut(seq_along(x), n, labels = FALSE))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Secondly Data Processing\n",
    "\tA) Secondly Data Loading\n",
    "\tB) Secondly Data Aggregation\n",
    "\tC) Perfect Forecast Formation\n",
    "\tD) Clody - Clear-sky Intervals Separation\n",
    "\tE) Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### A) Secondly Data Loading:\n",
    "\n",
    "# Secondly Data\n",
    "d = 3\n",
    "h.first = 0 # 8:00 - 9:00\n",
    "h.last = 23\n",
    "\n",
    "# Read in the XLSX hourly files:\n",
    "for(i in h.first:h.last)\n",
    "{\n",
    "    # Define interval\n",
    "    ini = i\n",
    "    end = i+1\n",
    "\n",
    "    # Load data \n",
    "    str = paste('X.data',ini,'_',end,'_',d,' = read.xlsx2(\"../../Data/Original Data/DIA ',d,'/',ini,'_',end,'.xlsx\", sheetName = \"Datos\", header = T, dec=\",\")',sep = '')\n",
    "    eval(parse(text = str))\n",
    "\n",
    "    # Rename categories\n",
    "    str2 = paste('names(','X.data',ini,'_',end,'_',d,') <- c(\"fecha\",\"p.disp.pv\",\"p.cons.pv\",\"p.act.pv\")',sep = \"\")\n",
    "    eval(parse(text = str2))\n",
    "}\n",
    "\n",
    "\n",
    "# Process the PV generation: \n",
    "gen_seg = c()\n",
    "\n",
    "for(i in h.first:h.last)\n",
    "{\n",
    "    # Define interval\n",
    "    ini = i\n",
    "    end = i+1\n",
    "    \n",
    "    str = paste('X.data',ini,'_',end,'_',d,'$p.disp.pv <- as.numeric(gsub(\",\",\".\",levels(X.data',ini,'_',end,'_',d,'$p.disp.pv)))[X.data',ini,'_',end,'_',d,'$p.disp.pv]',sep = '')\n",
    "    eval(parse(text = str))\n",
    "    \n",
    "    # Correct missing values\n",
    "    len_final = 3600\n",
    "    str3 = paste('origin = X.data',ini,'_',end,'_',d,'$p.disp.pv',sep = \"\")\n",
    "    eval(parse(text = str3))\n",
    "    \n",
    "    origin <- origin[!is.na(origin)]\n",
    "    out = approx(0:(length(origin)-1)/(length(origin)-1),origin, xout = 0:(len_final-1)/(len_final-1))\n",
    "    \n",
    "    gen_seg = c(gen_seg,out$y)\n",
    "    \n",
    "    str3 = paste('rm(X.data',ini,'_',end,'_',d,')',sep = \"\")\n",
    "    eval(parse(text = str3))\n",
    "}\n",
    "\n",
    "rm(d,h.first,h.last)\n",
    "\n",
    "# plot(gen_seg,type=\"l\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot(gen_seg,type=\"l\")\n",
    "# plot(gen_seg*GEN_REDUCTION,type=\"l\")\n",
    "\n",
    "gen_seg <- gen_seg*GEN_REDUCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### B) Secondly Data Aggregation:\n",
    "\n",
    "# calculate mean 5min generation (group sec in 5min block, and find mean)\n",
    "gen_seg_5min <- sapply(chunk(gen_seg,length(gen_seg)/t.ems.seg),mean)\n",
    "# calculate mean 30s generation (from secondly data)\n",
    "gen_seg_30seg <- sapply(chunk(gen_seg,length(gen_seg)/t.int.seg),mean)\n",
    "# calculate mean 30min generation (from secondly data)\n",
    "gen_seg_for <- sapply(chunk(gen_seg,length(gen_seg)/t.for.seg),mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### C) Perfect Forecast Formation:\n",
    "\n",
    "# Calculate the perfect 30min->30s forecast:\n",
    "gen_perf_for_30seg <- spline(1:length(gen_seg_for), gen_seg_for, n = length(gen_seg_30seg))$y\n",
    "\n",
    "# Calculate the perfect forecast errors:\n",
    "gen_err_30seg <- gen_seg_30seg -gen_perf_for_30seg\n",
    "gen_err_30seg_x41 = chunk(gen_err_30seg,my.41)\n",
    "# gen_err_30seg_x288 = chunk(gen_err_30seg,my.288)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### D) Clody - Clear-sky Intervals Separation:\n",
    "\n",
    "# We need to separate them because we model them differently:\n",
    "\n",
    "# For each 30min interval -> we calculate the Variance and compare it to treshold\n",
    "# (cloudy intervals will have a high variance, while clearsky will have a low one)\n",
    "\n",
    "# var.treshold <- 200000\n",
    "\n",
    "# We chunk the secondly data to 30min intervals, calc the var, and compare to treshold:\n",
    "mesos.nuvols   <- which(as.vector(sapply(chunk(gen_seg,my.41),var))>var.treshold) # which - returns index\n",
    "mesos.clearsky <- setdiff(1:my.41,mesos.nuvols)\n",
    "\n",
    "# Separate the perfect error to clody and clearsky intervals as well:\n",
    "gen.err.nuvols   <- gen_err_30seg[melt(gen_err_30seg_x41)$L1%in%mesos.nuvols]   # melt() - dechunkifies by index L1\n",
    "gen.err.clearsky <- gen_err_30seg[melt(gen_err_30seg_x41)$L1%in%mesos.clearsky]\n",
    "# melt() - turns the grouped object in a regular structures where $value = value and $L1 = group (chunk) index\n",
    "\n",
    "# par(mfrow=c(1,2))\n",
    "# hist(gen.err.nuvols,breaks = 25, main = \"Error for cloudy intervals\")\n",
    "# hist(gen.err.clearsky,breaks = 25, main = \"Error for clear sky intervals\")\n",
    "# par(mfrow=c(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### E) Model Fitting:\n",
    "\n",
    "# -------------------------------------------------------------#\n",
    "#  CLOUDY   intervals -> modelled with  BETA  distribution !!! #\n",
    "#  CLEARSKY intervals -> modelled with NORMAL distribution !!! #\n",
    "# -------------------------------------------------------------#\n",
    "\n",
    "## I) Cloudy - Beta Fitting:\n",
    "\n",
    "# To limit overfitting for the beta distribution -> we remove the top and bottom 10% extremes [outlier effect]\n",
    "gen.lim <- as.vector(quantile(sort(gen.err.nuvols),probs = c(0.1,0.9))) # returns us the 10% and 90% error value\n",
    "# gen.lim <- as.vector(quantile(sort(gen.err.nuvols),probs = c(0.05,0.95))) # returns us the 10% and 90% error value\n",
    "gen.err.nuvols.cent <- gen.err.nuvols[(gen.err.nuvols>= gen.lim[1])&(gen.err.nuvols< gen.lim[2])]\n",
    "\n",
    "# Convert to PU with min and max:\n",
    "max.gen.err <- max(gen.err.nuvols.cent)\n",
    "min.gen.err <- min(gen.err.nuvols.cent)\n",
    "gen.err.nuvols.norm <- (gen.err.nuvols.cent-min.gen.err)/(max.gen.err-min.gen.err)\n",
    "\n",
    "# Define the system of nonlinear equations for alpha and beta fitting:\n",
    "fn2 <- function(x)\n",
    "{\n",
    "  y1 <- x[1]/(x[1]+x[2]) - mean(gen.err.nuvols.norm)\n",
    "  # x[1]/(x[1]+x[2]) = mean(gen.err.nuvols.norm)\n",
    "  y2 <- x[1]*x[2]/((x[1]+x[2])^2*(x[1]+x[2]+1)) - var(gen.err.nuvols.norm)\n",
    "  # x[1]*x[2]/((x[1]+x[2])^2*(x[1]+x[2]+1)) = var(gen.err.nuvols.norm)\n",
    "  y = c(y1,y2)\n",
    "  return(y)\n",
    "}\n",
    "\n",
    "# Solve the system:\n",
    "sol<- nleqslv(c(0.2,0.2),fn2) # Solves it to make fn2 = 0\n",
    "gen.shape1 <- sol$x[1]\n",
    "gen.shape2 <- sol$x[2]\n",
    "\n",
    "## I) Clear-sky - Normal Fitting:\n",
    "\n",
    "mean_err_gen_perf <- mean(gen.err.clearsky)\n",
    "sd_err_gen_perf <- sd(gen.err.clearsky)\n",
    "\n",
    "## Finally we have alpha and beta for hours with clouds (beta) # error !!!!\n",
    "## We have the sd for clearsky hours (normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rm(\"fn2\",\"gen.err.clearsky\",\"gen.err.nuvols\",\"gen.err.nuvols.cent\",\"gen.err.nuvols.norm\",\"gen.lim\",\"gen_err_30seg\",\"gen_err_30seg_x41\",\"gen_perf_for_30seg\",\"i\",\"ini\",\"len_final\",\"origin\",\"out\",\"sol\",\"str\",\"str2\",\"str3\",\"var.treshold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) PV Scenarios Generation\n",
    "    A) Initialize the scenario matrices\n",
    "    B) Separate the cloudy and clearsky\n",
    "    C) Generate 24h ahead scenarios for each EMS period\n",
    "    D) Save the obtained data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### A) Initialize the scenario matrices:\n",
    "\n",
    "scen.gen <- matrix(0,nrow = my.2880, ncol = n_scen)\n",
    "scen.gen.all <- array(rep(1, my.2880*n_scen*my.288), dim=c(my.2880, n_scen, my.288))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### B) Separate the cloudy and clearsky:\n",
    "\n",
    "# Calculate the perfect 24h forecast:\n",
    "for.gen.long <- spline(1:length(gen_seg_for), gen_seg_for, n = my.2880)$y\n",
    "\n",
    "# Create a weather vector ()\n",
    "h.weather <- matrix(FALSE,nrow=1,ncol=my.41)\n",
    "h.weather[mesos.nuvols] = TRUE\n",
    "h.weather.large <- enlarge(h.weather,t.for/t.int) # stretch the vector to 30s intervals\n",
    "\n",
    "d.t = t.ems/t.int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### C) Create 24h ahead scenarios for each EMS period:\n",
    "\n",
    "for(p in 1:my.288)\n",
    "{    \n",
    "    for(i in 1:n_scen)\n",
    "    {\n",
    "        ## long term (35min) randomness:\n",
    "\n",
    "        # Generation (based on perfect 35min forecasts, splined to 2880 points)\n",
    "        scen.gen[,i] <- for.gen.long\n",
    "\n",
    "        ### Short term (30s) randomness:\n",
    "        # Cloudy Generation - Beta\n",
    "        scen.gen[as.logical(h.weather.large),i] <- (scen.gen[as.logical(h.weather.large),i] + (min.gen.err+(max.gen.err-min.gen.err)*rbeta(length(scen.gen[h.weather.large,i]),shape1 = gen.shape1 , shape2 = gen.shape2)))\n",
    "        # Clear-sky Generation - Normal\n",
    "        scen.gen[!h.weather.large,i] <-  scen.gen[!h.weather.large,i] + rnorm(length( scen.gen[!h.weather.large,i]),mean = 0, sd = sd_err_gen_perf)\n",
    "\n",
    "        # Limit to 0 (not going below 0)\n",
    "        scen.gen[,i] = pmax(scen.gen[,i],0)\n",
    "        # Remove the night hours:\n",
    "        scen.gen[for.gen.long<100,i] = 0\n",
    "        \n",
    "        # Shift to match current T_EMS:\n",
    "        n = (p-1)*d.t\n",
    "        if(n!=0)\n",
    "        {\n",
    "            scen.gen[,i] <- c(tail(scen.gen[,i], -n), head(scen.gen[,i], n))\n",
    "        }\n",
    "    }\n",
    "    scen.gen.all[,,p] <- scen.gen\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### D) Save the obtained data:\n",
    "\n",
    "# writeMat(gen_seg = gen_seg, con=\"../../Data/Generated Data/1 - Secondly/gen_seg.mat\")\n",
    "writeMat(gen_seg_org = gen_seg, con=\"../../Data/Generated Data/1 - Secondly/gen_seg_org.mat\")\n",
    "writeMat(gen_scen = scen.gen.all, con=\"../../Data/Generated Data/2 - Scenarios/gen_scen.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen.all = gen_seg\n",
    "save(\"gen.all\",file=\"../../Data/Generated Data/1 - Secondly/gen_seg_org.Rdata\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
